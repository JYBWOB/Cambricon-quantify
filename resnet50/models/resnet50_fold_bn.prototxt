layer {
name:"input_1"
top:"input_1"
type: "Input"
input_param {
    shape {
        dim: 1
        dim: 3
        dim: 224
        dim: 224
    }
}
}
layer {
name:"conv1"
top:"conv1"
type: "Convolution"
bottom: "input_1"
convolution_param {
    num_output: 64
    pad_h: 3
    pad_w: 3
    kernel_size: 7
    stride: 2
}
}
layer {
name:"activation_1"
top:"activation_1"
type: "ReLU"
bottom: "conv1"
}
layer {
name:"max_pooling2d_1"
top:"max_pooling2d_1"
type: "Pooling"
bottom: "activation_1"
pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad_h: 1
    pad_w: 1
}
}

layer {
  name:"slice1"
  type:"Slice"
  bottom:"max_pooling2d_1"
  top:"slice1"
  top:"slice_tmp1"
  slice_param {
    axis:2
    slice_point:56
  }
}

layer {
  name:"slice2"
  type:"Slice"
  bottom:"slice1"
  top:"slice2"
  top:"slice_tmp2"
  slice_param {
    axis:3
    slice_point:56
  }
}

layer {
name:"res2a_branch2a"
top:"res2a_branch2a"
type: "Convolution"
bottom: "slice2"
convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_2"
top:"activation_2"
type: "ReLU"
bottom: "res2a_branch2a"
}
layer {
name:"res2a_branch2b"
top:"res2a_branch2b"
type: "Convolution"
bottom: "activation_2"
convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_3"
top:"activation_3"
type: "ReLU"
bottom: "res2a_branch2b"
}
layer {
name:"res2a_branch2c"
top:"res2a_branch2c"
type: "Convolution"
bottom: "activation_3"
convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"res2a_branch1"
top:"res2a_branch1"
type: "Convolution"
bottom: "slice2"
convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_1"
top:"add_1"
bottom: "res2a_branch2c"
bottom: "res2a_branch1"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_4"
top:"activation_4"
type: "ReLU"
bottom: "add_1"
}
layer {
name:"res2b_branch2a"
top:"res2b_branch2a"
type: "Convolution"
bottom: "activation_4"
convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_5"
top:"activation_5"
type: "ReLU"
bottom: "res2b_branch2a"
}
layer {
name:"res2b_branch2b"
top:"res2b_branch2b"
type: "Convolution"
bottom: "activation_5"
convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_6"
top:"activation_6"
type: "ReLU"
bottom: "res2b_branch2b"
}
layer {
name:"res2b_branch2c"
top:"res2b_branch2c"
type: "Convolution"
bottom: "activation_6"
convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_2"
top:"add_2"
bottom: "res2b_branch2c"
bottom: "activation_4"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_7"
top:"activation_7"
type: "ReLU"
bottom: "add_2"
}
layer {
name:"res2c_branch2a"
top:"res2c_branch2a"
type: "Convolution"
bottom: "activation_7"
convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_8"
top:"activation_8"
type: "ReLU"
bottom: "res2c_branch2a"
}
layer {
name:"res2c_branch2b"
top:"res2c_branch2b"
type: "Convolution"
bottom: "activation_8"
convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_9"
top:"activation_9"
type: "ReLU"
bottom: "res2c_branch2b"
}
layer {
name:"res2c_branch2c"
top:"res2c_branch2c"
type: "Convolution"
bottom: "activation_9"
convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_3"
top:"add_3"
bottom: "res2c_branch2c"
bottom: "activation_7"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_10"
top:"activation_10"
type: "ReLU"
bottom: "add_3"
}
layer {
name:"res3a_branch2a"
top:"res3a_branch2a"
type: "Convolution"
bottom: "activation_10"
convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 2
}
}
layer {
name:"activation_11"
top:"activation_11"
type: "ReLU"
bottom: "res3a_branch2a"
}
layer {
name:"res3a_branch2b"
top:"res3a_branch2b"
type: "Convolution"
bottom: "activation_11"
convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_12"
top:"activation_12"
type: "ReLU"
bottom: "res3a_branch2b"
}
layer {
name:"res3a_branch2c"
top:"res3a_branch2c"
type: "Convolution"
bottom: "activation_12"
convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"res3a_branch1"
top:"res3a_branch1"
type: "Convolution"
bottom: "activation_10"
convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 2
}
}
layer {
name:"add_4"
top:"add_4"
bottom: "res3a_branch2c"
bottom: "res3a_branch1"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_13"
top:"activation_13"
type: "ReLU"
bottom: "add_4"
}
layer {
name:"res3b_branch2a"
top:"res3b_branch2a"
type: "Convolution"
bottom: "activation_13"
convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_14"
top:"activation_14"
type: "ReLU"
bottom: "res3b_branch2a"
}
layer {
name:"res3b_branch2b"
top:"res3b_branch2b"
type: "Convolution"
bottom: "activation_14"
convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_15"
top:"activation_15"
type: "ReLU"
bottom: "res3b_branch2b"
}
layer {
name:"res3b_branch2c"
top:"res3b_branch2c"
type: "Convolution"
bottom: "activation_15"
convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_5"
top:"add_5"
bottom: "res3b_branch2c"
bottom: "activation_13"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_16"
top:"activation_16"
type: "ReLU"
bottom: "add_5"
}
layer {
name:"res3c_branch2a"
top:"res3c_branch2a"
type: "Convolution"
bottom: "activation_16"
convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_17"
top:"activation_17"
type: "ReLU"
bottom: "res3c_branch2a"
}
layer {
name:"res3c_branch2b"
top:"res3c_branch2b"
type: "Convolution"
bottom: "activation_17"
convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_18"
top:"activation_18"
type: "ReLU"
bottom: "res3c_branch2b"
}
layer {
name:"res3c_branch2c"
top:"res3c_branch2c"
type: "Convolution"
bottom: "activation_18"
convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_6"
top:"add_6"
bottom: "res3c_branch2c"
bottom: "activation_16"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_19"
top:"activation_19"
type: "ReLU"
bottom: "add_6"
}
layer {
name:"res3d_branch2a"
top:"res3d_branch2a"
type: "Convolution"
bottom: "activation_19"
convolution_param {
    num_output: 128
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_20"
top:"activation_20"
type: "ReLU"
bottom: "res3d_branch2a"
}
layer {
name:"res3d_branch2b"
top:"res3d_branch2b"
type: "Convolution"
bottom: "activation_20"
convolution_param {
    num_output: 128
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_21"
top:"activation_21"
type: "ReLU"
bottom: "res3d_branch2b"
}
layer {
name:"res3d_branch2c"
top:"res3d_branch2c"
type: "Convolution"
bottom: "activation_21"
convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_7"
top:"add_7"
bottom: "res3d_branch2c"
bottom: "activation_19"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_22"
top:"activation_22"
type: "ReLU"
bottom: "add_7"
}
layer {
name:"res4a_branch2a"
top:"res4a_branch2a"
type: "Convolution"
bottom: "activation_22"
convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 2
}
}
layer {
name:"activation_23"
top:"activation_23"
type: "ReLU"
bottom: "res4a_branch2a"
}
layer {
name:"res4a_branch2b"
top:"res4a_branch2b"
type: "Convolution"
bottom: "activation_23"
convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_24"
top:"activation_24"
type: "ReLU"
bottom: "res4a_branch2b"
}
layer {
name:"res4a_branch2c"
top:"res4a_branch2c"
type: "Convolution"
bottom: "activation_24"
convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"res4a_branch1"
top:"res4a_branch1"
type: "Convolution"
bottom: "activation_22"
convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 2
}
}
layer {
name:"add_8"
top:"add_8"
bottom: "res4a_branch2c"
bottom: "res4a_branch1"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_25"
top:"activation_25"
type: "ReLU"
bottom: "add_8"
}
layer {
name:"res4b_branch2a"
top:"res4b_branch2a"
type: "Convolution"
bottom: "activation_25"
convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_26"
top:"activation_26"
type: "ReLU"
bottom: "res4b_branch2a"
}
layer {
name:"res4b_branch2b"
top:"res4b_branch2b"
type: "Convolution"
bottom: "activation_26"
convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_27"
top:"activation_27"
type: "ReLU"
bottom: "res4b_branch2b"
}
layer {
name:"res4b_branch2c"
top:"res4b_branch2c"
type: "Convolution"
bottom: "activation_27"
convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_9"
top:"add_9"
bottom: "res4b_branch2c"
bottom: "activation_25"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_28"
top:"activation_28"
type: "ReLU"
bottom: "add_9"
}
layer {
name:"res4c_branch2a"
top:"res4c_branch2a"
type: "Convolution"
bottom: "activation_28"
convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_29"
top:"activation_29"
type: "ReLU"
bottom: "res4c_branch2a"
}
layer {
name:"res4c_branch2b"
top:"res4c_branch2b"
type: "Convolution"
bottom: "activation_29"
convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_30"
top:"activation_30"
type: "ReLU"
bottom: "res4c_branch2b"
}
layer {
name:"res4c_branch2c"
top:"res4c_branch2c"
type: "Convolution"
bottom: "activation_30"
convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_10"
top:"add_10"
bottom: "res4c_branch2c"
bottom: "activation_28"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_31"
top:"activation_31"
type: "ReLU"
bottom: "add_10"
}
layer {
name:"res4d_branch2a"
top:"res4d_branch2a"
type: "Convolution"
bottom: "activation_31"
convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_32"
top:"activation_32"
type: "ReLU"
bottom: "res4d_branch2a"
}
layer {
name:"res4d_branch2b"
top:"res4d_branch2b"
type: "Convolution"
bottom: "activation_32"
convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_33"
top:"activation_33"
type: "ReLU"
bottom: "res4d_branch2b"
}
layer {
name:"res4d_branch2c"
top:"res4d_branch2c"
type: "Convolution"
bottom: "activation_33"
convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_11"
top:"add_11"
bottom: "res4d_branch2c"
bottom: "activation_31"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_34"
top:"activation_34"
type: "ReLU"
bottom: "add_11"
}
layer {
name:"res4e_branch2a"
top:"res4e_branch2a"
type: "Convolution"
bottom: "activation_34"
convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_35"
top:"activation_35"
type: "ReLU"
bottom: "res4e_branch2a"
}
layer {
name:"res4e_branch2b"
top:"res4e_branch2b"
type: "Convolution"
bottom: "activation_35"
convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_36"
top:"activation_36"
type: "ReLU"
bottom: "res4e_branch2b"
}
layer {
name:"res4e_branch2c"
top:"res4e_branch2c"
type: "Convolution"
bottom: "activation_36"
convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_12"
top:"add_12"
bottom: "res4e_branch2c"
bottom: "activation_34"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_37"
top:"activation_37"
type: "ReLU"
bottom: "add_12"
}
layer {
name:"res4f_branch2a"
top:"res4f_branch2a"
type: "Convolution"
bottom: "activation_37"
convolution_param {
    num_output: 256
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_38"
top:"activation_38"
type: "ReLU"
bottom: "res4f_branch2a"
}
layer {
name:"res4f_branch2b"
top:"res4f_branch2b"
type: "Convolution"
bottom: "activation_38"
convolution_param {
    num_output: 256
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_39"
top:"activation_39"
type: "ReLU"
bottom: "res4f_branch2b"
}
layer {
name:"res4f_branch2c"
top:"res4f_branch2c"
type: "Convolution"
bottom: "activation_39"
convolution_param {
    num_output: 1024
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_13"
top:"add_13"
bottom: "res4f_branch2c"
bottom: "activation_37"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_40"
top:"activation_40"
type: "ReLU"
bottom: "add_13"
}
layer {
name:"res5a_branch2a"
top:"res5a_branch2a"
type: "Convolution"
bottom: "activation_40"
convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 2
}
}
layer {
name:"activation_41"
top:"activation_41"
type: "ReLU"
bottom: "res5a_branch2a"
}
layer {
name:"res5a_branch2b"
top:"res5a_branch2b"
type: "Convolution"
bottom: "activation_41"
convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_42"
top:"activation_42"
type: "ReLU"
bottom: "res5a_branch2b"
}
layer {
name:"res5a_branch2c"
top:"res5a_branch2c"
type: "Convolution"
bottom: "activation_42"
convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"res5a_branch1"
top:"res5a_branch1"
type: "Convolution"
bottom: "activation_40"
convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 2
}
}
layer {
name:"add_14"
top:"add_14"
bottom: "res5a_branch2c"
bottom: "res5a_branch1"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_43"
top:"activation_43"
type: "ReLU"
bottom: "add_14"
}
layer {
name:"res5b_branch2a"
top:"res5b_branch2a"
type: "Convolution"
bottom: "activation_43"
convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_44"
top:"activation_44"
type: "ReLU"
bottom: "res5b_branch2a"
}
layer {
name:"res5b_branch2b"
top:"res5b_branch2b"
type: "Convolution"
bottom: "activation_44"
convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_45"
top:"activation_45"
type: "ReLU"
bottom: "res5b_branch2b"
}
layer {
name:"res5b_branch2c"
top:"res5b_branch2c"
type: "Convolution"
bottom: "activation_45"
convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_15"
top:"add_15"
bottom: "res5b_branch2c"
bottom: "activation_43"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_46"
top:"activation_46"
type: "ReLU"
bottom: "add_15"
}
layer {
name:"res5c_branch2a"
top:"res5c_branch2a"
type: "Convolution"
bottom: "activation_46"
convolution_param {
    num_output: 512
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"activation_47"
top:"activation_47"
type: "ReLU"
bottom: "res5c_branch2a"
}
layer {
name:"res5c_branch2b"
top:"res5c_branch2b"
type: "Convolution"
bottom: "activation_47"
convolution_param {
    num_output: 512
    pad: 1
    kernel_size: 3
    stride: 1
}
}
layer {
name:"activation_48"
top:"activation_48"
type: "ReLU"
bottom: "res5c_branch2b"
}
layer {
name:"res5c_branch2c"
top:"res5c_branch2c"
type: "Convolution"
bottom: "activation_48"
convolution_param {
    num_output: 2048
    pad: 0
    kernel_size: 1
    stride: 1
}
}
layer {
name:"add_16"
top:"add_16"
bottom: "res5c_branch2c"
bottom: "activation_46"
type: "Eltwise"
eltwise_param {
    operation: SUM
}
}
layer {
name:"activation_49"
top:"activation_49"
type: "ReLU"
bottom: "add_16"
}
layer {
name:"avg_pool"
top:"avg_pool"
type: "Pooling"
bottom: "activation_49"
pooling_param {
    pool: AVE
    global_pooling: true
}
}
layer {
name:"fc1000"
top:"fc1000"
type: "InnerProduct"
bottom: "avg_pool"
inner_product_param {
    num_output: 1000
}
}
layer {
name: "fc1000_relu"
type: "Softmax"
bottom: "fc1000"
top: "fc1000"
}
